"""
Delivery Adapter

Transforms build_scenario_pipeline output into three delivery formats:
  1. GitHub-safe artifact bundle (repo-ready files + commit metadata)
  2. Lovable ticket comment payload (markdown comment for CS tickets)
  3. Public demo-ready output (sanitized, customer-facing)

Input:
    pipeline_result (dict) — from build_scenario_pipeline
    spec (dict)            — canonical spec
    blueprint (dict)       — Make.com export JSON
    timeline (dict|None)   — from timeline_estimator
    cost (dict|None)       — from cost_estimator

No rebuild logic. No validation logic. No network calls. Deterministic.
"""

import copy
import json
import re


# --- GitHub Bundle ---

def adapt_for_github(pipeline_result, spec, blueprint, timeline=None, cost=None):
    """Transform pipeline output into a GitHub-safe artifact bundle.

    Returns:
        dict with:
            - repo_path: str (relative directory path for repo)
            - files: dict[filename → content_str] (all JSON-serialized)
            - commit_message: str
            - branch_name: str
    """
    slug = pipeline_result.get("slug", "untitled")
    version = pipeline_result.get("version", 1)
    confidence = pipeline_result.get("confidence", {})

    # Sanitize spec: strip absolute output_path from metadata
    safe_spec = copy.deepcopy(spec)
    if "metadata" in safe_spec:
        safe_spec["metadata"].pop("build_version", None)

    # Sanitize blueprint: no changes needed (already placeholder-based)
    safe_blueprint = copy.deepcopy(blueprint)

    # Build file dict (all values are JSON strings)
    files = {
        "make_export.json": json.dumps(safe_blueprint, indent=2, default=str),
        "canonical_spec.json": json.dumps(safe_spec, indent=2, default=str),
        "confidence.json": json.dumps(confidence, indent=2, default=str),
        "README.md": _github_readme(pipeline_result, spec, timeline, cost),
    }

    if timeline:
        files["timeline.json"] = json.dumps(timeline, indent=2, default=str)
    if cost:
        files["cost_estimate.json"] = json.dumps(cost, indent=2, default=str)

    # Commit metadata
    scenario_name = spec.get("scenario", {}).get("name", slug)
    grade = confidence.get("grade", "?")
    commit_message = (
        f"build({slug}): v{version} — {scenario_name}\n\n"
        f"Confidence: {confidence.get('score', '?')} (Grade {grade})\n"
        f"Modules: {len(spec.get('modules', []))}\n"
        f"Generated by Agentic Make Builder"
    )

    branch_name = f"build/{slug}-v{version}"

    return {
        "repo_path": f"scenarios/{slug}/v{version}/",
        "files": files,
        "commit_message": commit_message,
        "branch_name": branch_name,
    }


def _github_readme(pipeline_result, spec, timeline, cost):
    """Generate a README.md for the GitHub artifact bundle."""
    scenario = spec.get("scenario", {})
    trigger = spec.get("trigger", {})
    modules = spec.get("modules", [])
    confidence = pipeline_result.get("confidence", {})

    lines = [
        f"# {scenario.get('name', 'Untitled Scenario')}",
        "",
        f"> {scenario.get('description', 'No description')}",
        "",
        "## Overview",
        "",
        f"| Field | Value |",
        f"|-------|-------|",
        f"| Slug | `{scenario.get('slug', 'unknown')}` |",
        f"| Version | v{pipeline_result.get('version', '?')} |",
        f"| Confidence | {confidence.get('score', '?')} (Grade {confidence.get('grade', '?')}) |",
        f"| Trigger | {trigger.get('label', 'N/A')} (`{trigger.get('module', 'N/A')}`) |",
        f"| Modules | {len(modules)} |",
        f"| Connections | {len(spec.get('connections', []))} |",
        "",
    ]

    if modules:
        lines.extend(["## Modules", ""])
        for mod in modules:
            cred = f" (requires `{mod['credential_placeholder']}`)" if mod.get("credential_placeholder") else ""
            lines.append(f"- **{mod['label']}** — `{mod['module']}`{cred}")
        lines.append("")

    if timeline:
        lines.extend([
            "## Timeline",
            "",
            f"- **Estimated:** {timeline.get('total_hours', '?')} hours",
            f"- **Complexity:** {timeline.get('complexity_grade', '?').title()}",
            "",
        ])

    if cost:
        plan = cost.get("recommended_plan", {})
        lines.extend([
            "## Cost",
            "",
            f"- **Ops/execution:** {cost.get('ops_per_execution', '?')}",
            f"- **Recommended plan:** Make.com {plan.get('name', '?')} (${cost.get('monthly_operational_cost', 0):.2f}/mo)",
            "",
        ])

    lines.extend([
        "## Files",
        "",
        "| File | Description |",
        "|------|-------------|",
        "| `make_export.json` | Importable Make.com blueprint |",
        "| `canonical_spec.json` | Normalized workflow specification |",
        "| `confidence.json` | Build confidence score |",
        "| `timeline.json` | Implementation timeline estimate |",
        "| `cost_estimate.json` | Operational cost estimate |",
        "",
        "---",
        "",
        "*Generated by Agentic Make Builder*",
    ])

    return "\n".join(lines)


# --- Ticket Comment Payload ---

def adapt_for_ticket(pipeline_result, spec, timeline=None, cost=None):
    """Transform pipeline output into a ticket comment payload.

    Returns:
        dict with:
            - title: str
            - body_md: str (markdown-formatted comment body)
            - status: str ("ready_for_review", "needs_revision", "failed")
            - labels: list[str]
            - priority: str ("low", "medium", "high")
    """
    scenario = spec.get("scenario", {})
    slug = pipeline_result.get("slug", "untitled")
    confidence = pipeline_result.get("confidence", {})
    success = pipeline_result.get("success", False)

    # Determine status
    if not success:
        status = "failed"
    elif confidence.get("grade") in ("A", "B"):
        status = "ready_for_review"
    else:
        status = "needs_revision"

    # Title
    grade = confidence.get("grade", "?")
    title = f"[Build {_status_emoji(status)}] {scenario.get('name', slug)} — Grade {grade}"

    # Body
    body_md = _ticket_body(pipeline_result, spec, timeline, cost, status)

    # Labels
    labels = [f"grade-{grade.lower()}" if grade != "?" else "grade-unknown"]
    if any(m.get("module_type") == "flow_control" for m in spec.get("modules", [])):
        labels.append("has-routing")
    creds = [m.get("credential_placeholder") for m in spec.get("modules", []) if m.get("credential_placeholder")]
    if creds:
        labels.append("requires-credentials")
    labels.append(f"status-{status.replace('_', '-')}")

    # Priority
    if status == "failed":
        priority = "high"
    elif status == "needs_revision":
        priority = "medium"
    else:
        priority = "low"

    return {
        "title": title,
        "body_md": body_md,
        "status": status,
        "labels": labels,
        "priority": priority,
    }


def _status_emoji(status):
    """Return a text status indicator (no actual emojis)."""
    return {
        "ready_for_review": "READY",
        "needs_revision": "REVISION",
        "failed": "FAILED",
    }.get(status, "UNKNOWN")


def _ticket_body(pipeline_result, spec, timeline, cost, status):
    """Generate markdown body for the ticket comment."""
    scenario = spec.get("scenario", {})
    trigger = spec.get("trigger", {})
    modules = spec.get("modules", [])
    confidence = pipeline_result.get("confidence", {})
    slug = pipeline_result.get("slug", "untitled")
    version = pipeline_result.get("version", "?")

    lines = [
        f"### Build Report: {scenario.get('name', slug)}",
        "",
        f"**Slug:** `{slug}` | **Version:** v{version} | "
        f"**Confidence:** {confidence.get('score', '?')} (Grade {confidence.get('grade', '?')})",
        "",
    ]

    # Status-specific header
    if status == "failed":
        lines.extend([
            f"> **Build failed.** {pipeline_result.get('failure_reason', 'Unknown error')}",
            "",
        ])
    elif status == "needs_revision":
        lines.extend([
            "> **Build completed with low confidence.** Please review before delivery.",
            "",
        ])

    # Validation summary
    cv = pipeline_result.get("canonical_validation", {})
    ev = pipeline_result.get("export_validation", {})
    lines.extend([
        "#### Validation",
        "",
        f"| Check | Result |",
        f"|-------|--------|",
        f"| Canonical Spec | {cv.get('checks_passed', '?')}/{cv.get('checks_run', '?')} |",
        f"| Make Export | {ev.get('checks_passed', '?')}/{ev.get('checks_run', '?')} |",
    ])

    heal = pipeline_result.get("heal_result")
    if heal:
        lines.append(f"| Self-Heal | {heal.get('repairs', 0)} repair(s) |")
    lines.append("")

    # Scenario structure
    lines.extend([
        "#### Scenario",
        "",
        f"- **Trigger:** {trigger.get('label', 'N/A')} (`{trigger.get('module', 'N/A')}`)",
    ])
    for mod in modules:
        lines.append(f"- **[{mod['id']}]** {mod['label']} (`{mod['module']}`)")
    lines.append("")

    # Timeline + cost
    if timeline:
        lines.append(
            f"**Timeline:** ~{timeline.get('total_hours', '?')} hours "
            f"({timeline.get('complexity_grade', '?').title()} complexity)"
        )
    if cost:
        plan = cost.get("recommended_plan", {})
        lines.append(
            f"**Cost:** {cost.get('ops_per_execution', '?')} ops/exec | "
            f"Make.com {plan.get('name', '?')} plan "
            f"(${cost.get('monthly_operational_cost', 0):.2f}/mo)"
        )
    if timeline or cost:
        lines.append("")

    # Credentials needed
    creds = sorted(set(
        m.get("credential_placeholder") for m in modules if m.get("credential_placeholder")
    ))
    if creds:
        lines.extend(["#### Credentials Required", ""])
        for c in creds:
            lines.append(f"- `{c}`")
        lines.append("")

    # Next steps
    lines.extend([
        "#### Next Steps",
        "",
    ])
    if status == "ready_for_review":
        lines.extend([
            "1. Review the blueprint and confirm it matches requirements",
            "2. Set up required credentials in Make.com",
            "3. Import `make_export.json` into Make.com",
            "4. Run a test execution",
        ])
    elif status == "needs_revision":
        lines.extend([
            "1. Review validation warnings and agent notes",
            "2. Clarify any ambiguous requirements",
            "3. Re-run the build with updated inputs",
        ])
    else:
        lines.extend([
            "1. Review the failure reason above",
            "2. Fix the underlying issue in the intake/plan",
            "3. Re-run the build",
        ])
    lines.append("")

    return "\n".join(lines)


# --- Public Demo Output ---

def adapt_for_demo(pipeline_result, spec, blueprint, timeline=None, cost=None):
    """Transform pipeline output into a public demo-ready structure.

    Sanitized: no absolute paths, no raw validation internals, no credential
    values. Emphasis on what was built and quality indicators.

    Returns:
        dict with:
            - scenario_name: str
            - description: str
            - highlights: list[str]
            - structure_summary: str
            - quality_badge: str
            - timeline: str | None
            - cost: str | None
            - blueprint_preview: dict (sanitized)
    """
    scenario = spec.get("scenario", {})
    trigger = spec.get("trigger", {})
    modules = spec.get("modules", [])
    confidence = pipeline_result.get("confidence", {})

    # Highlights
    highlights = _build_highlights(spec, pipeline_result, timeline, cost)

    # Structure summary (human-readable flow description)
    structure_summary = _build_structure_summary(trigger, modules, spec.get("connections", []))

    # Quality badge
    grade = confidence.get("grade", "?")
    score = confidence.get("score", 0)
    badge_labels = {
        "A": "Production Ready",
        "B": "Review Recommended",
        "C": "Needs Attention",
        "D": "Significant Issues",
        "F": "Build Failed",
    }
    quality_badge = f"Grade {grade} — {badge_labels.get(grade, 'Unknown')}"

    # Timeline string
    timeline_str = None
    if timeline:
        timeline_str = (
            f"~{timeline.get('total_hours', '?')} hours "
            f"({timeline.get('complexity_grade', '?').title()} complexity)"
        )

    # Cost string
    cost_str = None
    if cost:
        plan = cost.get("recommended_plan", {})
        cost_str = (
            f"${cost.get('monthly_operational_cost', 0):.2f}/mo "
            f"on Make.com {plan.get('name', '?')} plan"
        )

    # Blueprint preview: sanitized, no real credentials
    blueprint_preview = _sanitize_blueprint_for_demo(blueprint)

    return {
        "scenario_name": scenario.get("name", "Untitled Scenario"),
        "description": scenario.get("description", ""),
        "highlights": highlights,
        "structure_summary": structure_summary,
        "quality_badge": quality_badge,
        "timeline": timeline_str,
        "cost": cost_str,
        "blueprint_preview": blueprint_preview,
    }


def _build_highlights(spec, pipeline_result, timeline, cost):
    """Build a list of scenario highlights for demo display."""
    modules = spec.get("modules", [])
    trigger = spec.get("trigger", {})
    confidence = pipeline_result.get("confidence", {})
    highlights = []

    # Module count
    highlights.append(f"{len(modules)} processing step(s) fully configured")

    # Trigger type
    trigger_type = trigger.get("type", "webhook")
    highlights.append(f"Triggered by {trigger_type}")

    # Routing
    routers = [m for m in modules if m.get("module_type") == "flow_control"]
    if routers:
        highlights.append("Intelligent conditional routing")

    # Apps used
    apps = sorted(set(m.get("app", "unknown") for m in modules))
    external = [a for a in apps if a not in ("builtin", "json", "util", "gateway")]
    if external:
        highlights.append(f"Integrates with: {', '.join(external)}")

    # Confidence
    grade = confidence.get("grade", "?")
    if grade in ("A", "B"):
        highlights.append(f"Grade {grade} confidence — production ready")

    # Validation
    cv = pipeline_result.get("canonical_validation", {})
    ev = pipeline_result.get("export_validation", {})
    total_checks = cv.get("checks_run", 0) + ev.get("checks_run", 0)
    total_passed = cv.get("checks_passed", 0) + ev.get("checks_passed", 0)
    if total_checks > 0:
        highlights.append(f"Passed {total_passed}/{total_checks} validation checks")

    # Self-heal
    heal = pipeline_result.get("heal_result")
    if heal and heal.get("repairs", 0) > 0:
        highlights.append(f"Self-healed {heal['repairs']} issue(s) automatically")

    return highlights


def _build_structure_summary(trigger, modules, connections):
    """Build a human-readable flow description."""
    parts = [f"{trigger.get('label', 'Trigger')}"]

    for mod in modules:
        parts.append(mod.get("label", mod.get("module", "Unknown")))

    return " → ".join(parts)


def _sanitize_blueprint_for_demo(blueprint):
    """Create a sanitized blueprint preview for public demos.

    Removes: absolute paths, potential credential leaks.
    Preserves: structure, module names, flow logic.
    """
    safe = copy.deepcopy(blueprint)

    # Walk all modules in flow and routes, redact __IMTCONN__ values
    for mod in _iter_blueprint_modules(safe):
        params = mod.get("parameters", {})
        if isinstance(params, dict):
            for key in list(params.keys()):
                if key == "__IMTCONN__":
                    params[key] = {"__PLACEHOLDER__": True}

    # Strip metadata paths
    meta = safe.get("metadata", {})
    scenario = meta.get("scenario", {})
    if isinstance(scenario, dict):
        scenario.pop("dataloss", None)
        scenario.pop("dlq", None)

    return safe


def _iter_blueprint_modules(blueprint):
    """Yield all modules from a blueprint, including nested route flows."""
    for mod in blueprint.get("flow", []):
        yield mod
        if "routes" in mod:
            for route in mod.get("routes", []):
                for nested in route.get("flow", []):
                    yield nested


# --- Convenience wrapper ---

def adapt_all(pipeline_result, spec, blueprint, timeline=None, cost=None):
    """Generate all three delivery formats at once.

    Returns:
        dict with github, ticket, demo keys.
    """
    return {
        "github": adapt_for_github(pipeline_result, spec, blueprint, timeline, cost),
        "ticket": adapt_for_ticket(pipeline_result, spec, timeline, cost),
        "demo": adapt_for_demo(pipeline_result, spec, blueprint, timeline, cost),
    }


# --- Self-check ---
if __name__ == "__main__":
    print("=== Delivery Adapter Self-Check ===\n")

    import tempfile
    import shutil
    from tools.module_registry_loader import load_module_registry
    from tools.build_scenario_pipeline import build_scenario_pipeline

    registry = load_module_registry()

    # Build a real scenario through the pipeline to get authentic data
    plan = {
        "scenario_name": "Webhook to Slack Notifier",
        "scenario_description": "Parse incoming webhook JSON and post a notification to Slack.",
        "trigger": {
            "type": "webhook",
            "module": "gateway:CustomWebHook",
            "label": "Incoming Webhook",
            "parameters": {"hook": "__WEBHOOK_ID__"}
        },
        "steps": [
            {
                "module": "json:ParseJSON",
                "label": "Parse JSON Body",
                "mapper": {"json": "{{1.body}}"}
            },
            {
                "module": "slack:PostMessage",
                "label": "Notify Slack",
                "mapper": {"channel": "#alerts", "text": "New event: {{2.name}}"}
            }
        ],
        "error_handling": {"default_strategy": "ignore", "max_errors": 3},
        "agent_notes": ["Auto-resolved channel to #alerts"]
    }

    test_dir = tempfile.mkdtemp(prefix="amb_adapter_test_")
    try:
        result = build_scenario_pipeline(plan, registry, "Send webhook data to Slack",
                                         base_output_dir=test_dir)
        assert result["success"], f"Pipeline failed: {result['failure_reason']}"

        # Read back artifacts for adapter input
        import os
        vdir = result["output_path"]
        with open(os.path.join(vdir, "canonical_spec.json"), "r") as f:
            spec = json.load(f)
        with open(os.path.join(vdir, "make_export.json"), "r") as f:
            blueprint = json.load(f)
        with open(os.path.join(vdir, "timeline.json"), "r") as f:
            timeline = json.load(f)
        with open(os.path.join(vdir, "cost_estimate.json"), "r") as f:
            cost = json.load(f)

        # === Test 1: GitHub bundle ===
        print("Test 1: GitHub artifact bundle")
        gh = adapt_for_github(result, spec, blueprint, timeline, cost)

        assert gh["repo_path"] == f"scenarios/webhook-to-slack-notifier/v{result['version']}/"
        assert gh["branch_name"] == f"build/webhook-to-slack-notifier-v{result['version']}"
        assert "make_export.json" in gh["files"]
        assert "canonical_spec.json" in gh["files"]
        assert "confidence.json" in gh["files"]
        assert "README.md" in gh["files"]
        assert "timeline.json" in gh["files"]
        assert "cost_estimate.json" in gh["files"]
        assert len(gh["commit_message"]) > 0
        assert "webhook-to-slack-notifier" in gh["commit_message"]

        # Verify all file contents are valid JSON (except README)
        for fname, content in gh["files"].items():
            if fname.endswith(".json"):
                parsed = json.loads(content)
                assert isinstance(parsed, dict), f"{fname} not a dict"

        # Verify README content
        readme = gh["files"]["README.md"]
        assert "# Webhook to Slack Notifier" in readme
        assert "make_export.json" in readme

        print(f"  Repo path: {gh['repo_path']}")
        print(f"  Files: {list(gh['files'].keys())}")
        print(f"  Branch: {gh['branch_name']}")
        print(f"  Commit msg: {gh['commit_message'].splitlines()[0]}")
        print("  [OK]")

        # === Test 2: Ticket comment payload ===
        print("\nTest 2: Ticket comment payload")
        ticket = adapt_for_ticket(result, spec, timeline, cost)

        assert "READY" in ticket["title"]
        assert "Webhook to Slack Notifier" in ticket["title"]
        assert ticket["status"] == "ready_for_review"
        assert "grade-a" in ticket["labels"]
        assert "status-ready-for-review" in ticket["labels"]
        assert ticket["priority"] == "low"
        assert len(ticket["body_md"]) > 100
        assert "### Build Report" in ticket["body_md"]
        assert "Validation" in ticket["body_md"]
        assert "Next Steps" in ticket["body_md"]

        print(f"  Title: {ticket['title']}")
        print(f"  Status: {ticket['status']}")
        print(f"  Labels: {ticket['labels']}")
        print(f"  Priority: {ticket['priority']}")
        print(f"  Body: {len(ticket['body_md'])} chars")
        print("  [OK]")

        # === Test 3: Public demo output ===
        print("\nTest 3: Public demo output")
        demo = adapt_for_demo(result, spec, blueprint, timeline, cost)

        assert demo["scenario_name"] == "Webhook to Slack Notifier"
        assert len(demo["description"]) > 0
        assert len(demo["highlights"]) >= 3
        assert "Grade A" in demo["quality_badge"]
        assert "Production Ready" in demo["quality_badge"]
        assert demo["timeline"] is not None
        assert demo["cost"] is not None
        assert isinstance(demo["blueprint_preview"], dict)
        assert "flow" in demo["blueprint_preview"]
        assert demo["structure_summary"].startswith("Incoming Webhook")

        # Verify blueprint sanitized
        for mod in _iter_blueprint_modules(demo["blueprint_preview"]):
            params = mod.get("parameters", {})
            if "__IMTCONN__" in params:
                assert params["__IMTCONN__"] == {"__PLACEHOLDER__": True}, \
                    "Credential not sanitized"

        print(f"  Name: {demo['scenario_name']}")
        print(f"  Highlights: {len(demo['highlights'])}")
        for h in demo["highlights"]:
            print(f"    - {h}")
        print(f"  Quality: {demo['quality_badge']}")
        print(f"  Timeline: {demo['timeline']}")
        print(f"  Cost: {demo['cost']}")
        print(f"  Structure: {demo['structure_summary']}")
        print("  [OK]")

        # === Test 4: adapt_all convenience wrapper ===
        print("\nTest 4: adapt_all wrapper")
        all_formats = adapt_all(result, spec, blueprint, timeline, cost)

        assert "github" in all_formats
        assert "ticket" in all_formats
        assert "demo" in all_formats
        assert all_formats["github"]["repo_path"] == gh["repo_path"]
        assert all_formats["ticket"]["title"] == ticket["title"]
        assert all_formats["demo"]["scenario_name"] == demo["scenario_name"]
        print(f"  Keys: {list(all_formats.keys())}")
        print("  [OK]")

        # === Test 5: Failed build adapts gracefully ===
        print("\nTest 5: Failed build handling")
        failed_result = {
            "success": False,
            "slug": "broken-scenario",
            "version": 1,
            "output_path": "/tmp/fake",
            "confidence": {"score": 0.35, "grade": "F", "explanation": "Build failed"},
            "canonical_validation": {"checks_run": 48, "checks_passed": 30, "errors": 5, "warnings": 2},
            "export_validation": {"checks_run": 0, "checks_passed": 0, "errors": 0, "warnings": 0},
            "heal_result": None,
            "delivery_summary": "Build failed.",
            "failure_reason": "Canonical spec validation failed"
        }
        failed_spec = {
            "scenario": {"name": "Broken Scenario", "slug": "broken-scenario", "description": "Test"},
            "trigger": {"type": "webhook", "module": "gateway:CustomWebHook", "label": "Webhook"},
            "modules": [],
            "connections": [],
        }

        ft = adapt_for_ticket(failed_result, failed_spec)
        assert ft["status"] == "failed"
        assert ft["priority"] == "high"
        assert "FAILED" in ft["title"]
        assert "failed" in ft["body_md"].lower()

        fd = adapt_for_demo(failed_result, failed_spec, {"flow": []})
        assert "Grade F" in fd["quality_badge"]
        assert fd["timeline"] is None
        assert fd["cost"] is None

        print(f"  Ticket status: {ft['status']}, priority: {ft['priority']}")
        print(f"  Demo badge: {fd['quality_badge']}")
        print("  [OK]")

        # === Test 6: Determinism ===
        print("\nTest 6: Determinism")
        gh_a = adapt_for_github(result, spec, blueprint, timeline, cost)
        gh_b = adapt_for_github(result, spec, blueprint, timeline, cost)
        assert gh_a == gh_b

        tk_a = adapt_for_ticket(result, spec, timeline, cost)
        tk_b = adapt_for_ticket(result, spec, timeline, cost)
        assert tk_a == tk_b

        dm_a = adapt_for_demo(result, spec, blueprint, timeline, cost)
        dm_b = adapt_for_demo(result, spec, blueprint, timeline, cost)
        assert dm_a == dm_b

        print("  [OK]")

    finally:
        shutil.rmtree(test_dir)

    print("\n=== All delivery_adapter checks passed ===")
