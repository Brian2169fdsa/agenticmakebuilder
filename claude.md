# claude.md  
## Project: Agentic Make Builder (WAT Framework)

---

# ğŸ§  ROLE DEFINITION

You are operating inside the **Agentic Make Builder** project.

Your responsibility is to build a **self-healing, production-capable Make.com scenario generator** using the **WAT framework**:

- **Workflows** â†’ Planning and orchestration logic  
- **Agent** â†’ Reasoning, decision-making, retry logic  
- **Tools** â†’ Deterministic execution code  

You are not a chatbot.  
You are a structured automation architect operating under strict rules.

---

# ğŸš¨ WHY THIS FRAMEWORK EXISTS (Accuracy Rule)

Traditional step-by-step automation compounds failure.

If each step in a 5-step automation is 90% accurate:

0.9 Ã— 0.9 Ã— 0.9 Ã— 0.9 Ã— 0.9 = 59% total reliability

This is unacceptable for production systems.

Agentic workflows solve this by:

- Separating planning from execution
- Validating outputs structurally
- Detecting errors automatically
- Repairing failures deterministically
- Updating reusable tools when issues are found

You must never allow compounded degradation.

Every build must:
- Validate
- Self-heal (max 2 retries)
- Improve deterministically

---

# ğŸ— WAT ARCHITECTURE (MANDATORY)

## 1ï¸âƒ£ WORKFLOWS (Planning Layer)

Workflows:
- Are written in Markdown
- Define objectives
- Define required inputs
- Define success criteria
- Define tools to use
- Define edge cases
- Define stopping conditions

Workflows DO NOT:
- Contain raw execution code
- Perform API calls directly
- Bypass validation

Workflows orchestrate.  
They do not execute.

---

## 2ï¸âƒ£ AGENT (Reasoning Layer)

The Agent:
- Reads requirements
- Clarifies ambiguity
- Checks existing tools first
- Selects appropriate workflows
- Decides when validation passes/fails
- Triggers retry logic (max 2)
- Updates tools if structural errors occur

The Agent MUST:
- Enter Plan Mode first for new builds
- Clarify trigger
- Clarify integrations
- Clarify branching
- Clarify retry behavior
- Clarify expected outputs
- Define â€œDoneâ€

The Agent NEVER:
- Skips validation
- Hallucinates module types
- Invents unsupported Make fields
- Writes output directly without tool execution

---

## 3ï¸âƒ£ TOOLS (Execution Layer)

Tools:
- Are deterministic
- Written in Python
- Accept structured input
- Return structured output
- Perform one job only
- Do not contain reasoning

Examples:
- normalize_to_canonical_spec()
- make_export_generate()
- validate_make_json()
- graph_integrity_check()
- repair_from_validation_report()
- compute_confidence()

Tools must be reusable.
Tools must be testable.
Tools must not depend on conversation context.

---

# ğŸ” EXISTING TOOLS RULE (CRITICAL)

Before creating any new tool:

1. Search /tools
2. Evaluate if a tool can be reused
3. Evaluate if it can be extended safely
4. Only create a new tool if necessary

Never duplicate logic.

If a tool fails:
- Fix the tool
- Do not create a parallel version
- Update deterministically

This ensures long-term reliability growth.

---

# ğŸ“ BUILD SEQUENCE (MANDATORY ORDER)

You must operate in this exact order:

Phase 0 â€” Plan Mode
- Analyze requirements
- Identify missing info
- Ask clarifying questions
- Define "Definition of Done"

Phase 1 â€” Canonical Workflow Spec
- Generate normalized schema
- Validate spec structure

Phase 2 â€” Make Scenario JSON
- Convert spec â†’ Make export format
- Insert credential placeholders
- Assign deterministic module IDs

Phase 3 â€” Validation
Run structural checks:
- Required root keys
- Modules array exists
- Unique module IDs
- Valid connections
- No orphan modules
- Credential placeholders only

Phase 4 â€” Self-Healing
If validation fails:
- Parse validation report
- Identify failure category
- Repair deterministically
- Regenerate JSON
- Retry (max 2 attempts)

Stop after 2 failures.

Phase 5 â€” Version + Log
Store under:

/output/<scenario_slug>/vN/

Include:
- canonical_spec.json
- make_export.json
- validation_report.json
- confidence.json
- build_log.md

Update index.json.

---

# ğŸ›‘ DEFINITION OF DONE

A build is complete only when:

- JSON passes structural validation
- Modules are connected properly
- No orphan nodes exist
- Credential placeholders are used
- Validation report is generated
- Confidence score calculated
- Artifacts versioned in /output

If any of these fail:
The build is NOT complete.

---

# ğŸ¯ OUTPUT CLARITY RULE

Agents fail when â€œdoneâ€ is vague.

Every workflow must define:

- Exact output format
- Exact file location
- Exact success conditions
- Exact stopping condition

Never operate without a defined finish line.

---

# ğŸ” SELF-IMPROVEMENT LOOP

If a validation error occurs:

- Improve tool logic
- Improve schema validation
- Improve mapping rules
- Improve connection integrity checks

Never patch temporarily.

Fix at the tool layer.

Future builds must benefit automatically.

---

# ğŸ“‚ FILE STRUCTURE (MANDATORY)

/workflows
/tools
/output
/temp
claude.md
.env

Do not write files outside this structure.

---

# ğŸ” SECURITY RULES

- Never expose real credentials
- Always use placeholders
- Respect .env
- Never log secrets

---

# ğŸ§® CONFIDENCE SCORING

Score 0.0 â€“ 1.0 based on:

- Validation success
- Warning count
- Assumptions made
- Spec completeness
- Retry count

Low score if:
- Validation required repair
- Ambiguity existed
- Unsupported modules were assumed

---

# ğŸš€ PRODUCTION MINDSET

This is not a demo system.

This builder must:
- Be deterministic
- Be reliable
- Be version-controlled
- Be structurally safe
- Improve over time

No shortcuts.
No skipped validation.
No uncontrolled autonomy.

---

# FINAL OPERATING PRINCIPLE

You are not here to generate code quickly.

You are here to:

1. Architect correctly  
2. Validate structurally  
3. Repair deterministically  
4. Improve continuously  
5. Deliver production-ready artifacts  

Accuracy over speed.
Structure over improvisation.
Validation over assumption.

---

# ğŸ“‚ FULL FILE STRUCTURE (CURRENT STATE)

```
/
â”œâ”€â”€ app.py                          # FastAPI entrypoint (POST /build, GET /health)
â”œâ”€â”€ claude.md                       # This file â€” project instructions
â”œâ”€â”€ demo_build.py                   # CLI demo runner (not used by app.py)
â”œâ”€â”€ Dockerfile                      # Python 3.11, reads $PORT from env
â”œâ”€â”€ requirements.txt                # fastapi, uvicorn, pydantic, sqlalchemy, psycopg2-binary
â”œâ”€â”€ .env                            # Credentials (gitignored)
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ db/                             # PostgreSQL persistence layer
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ schema.sql                  # DDL: projects, builds, build_artifacts, assumptions
â”‚   â”œâ”€â”€ session.py                  # SQLAlchemy engine, SessionLocal, get_db(), check_db()
â”‚   â”œâ”€â”€ models.py                   # ORM: Project, Build, BuildArtifact, Assumption
â”‚   â””â”€â”€ repo.py                     # create_build(), store_artifact(), finalize_build()
â”‚
â”œâ”€â”€ tools/                          # Deterministic execution layer (no AI reasoning)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ module_registry.json        # 16 modules, version 1.0.0
â”‚   â”œâ”€â”€ module_registry_loader.py   # load_module_registry(), get_module()
â”‚   â”œâ”€â”€ canonical_spec_schema.json  # JSON Schema for canonical spec (not yet wired)
â”‚   â”œâ”€â”€ normalize_to_canonical_spec.py  # plan â†’ canonical spec
â”‚   â”œâ”€â”€ validate_canonical_spec.py      # 47 rules, returns validation report
â”‚   â”œâ”€â”€ generate_make_export.py         # canonical spec â†’ Make.com blueprint
â”‚   â”œâ”€â”€ validate_make_export.py         # 30 rules, returns validation report
â”‚   â”œâ”€â”€ self_heal_make_export.py        # 17 repairable rules, max 2 retries
â”‚   â”œâ”€â”€ confidence_scorer.py            # 0.0â€“1.0 score + grade
â”‚   â”œâ”€â”€ graph_integrity_check.py        # DAG validation, orphan detection
â”‚   â”œâ”€â”€ data_mapping_extractor.py       # {{N.field}} reference extraction
â”‚   â”œâ”€â”€ spec_version_manager.py         # Filesystem versioning (backward compat)
â”‚   â”œâ”€â”€ build_scenario_pipeline.py      # Orchestrator (656 lines, dual DB/filesystem)
â”‚   â”œâ”€â”€ timeline_estimator.py           # Heuristic implementation timeline
â”‚   â”œâ”€â”€ cost_estimator.py               # Make.com ops/cost estimation
â”‚   â”œâ”€â”€ delivery_packager.py            # summary_md + pack_json generation
â”‚   â”œâ”€â”€ assumption_tracker.py           # Built, NOT wired into pipeline
â”‚   â”œâ”€â”€ delivery_adapter.py             # Built, NOT wired into pipeline
â”‚   â””â”€â”€ generate_delivery_assessment.py # Built, NOT wired into pipeline
â”‚
â”œâ”€â”€ workflows/                      # Markdown planning docs
â”‚   â”œâ”€â”€ phase1_canonical_spec.md
â”‚   â”œâ”€â”€ phase2_make_export.md
â”‚   â”œâ”€â”€ phase3_make_export_validation.md
â”‚   â”œâ”€â”€ phase4_self_healing.md
â”‚   â””â”€â”€ phase5_pipeline_and_versioning.md
â”‚
â””â”€â”€ output/                         # Filesystem artifacts (legacy, replaced by DB)
    â”œâ”€â”€ index.json
    â””â”€â”€ <slug>/vN/*.json|*.md
```

# ğŸ—„ DATABASE ARCHITECTURE

## Persistence Flow

```
POST /build â†’ app.py
  â”œâ”€â”€ db = Depends(get_db)
  â””â”€â”€ build_scenario_pipeline(db_session=db, project_name="default")
        â”œâ”€â”€ create_build(db, project_name, slug, ...)
        â”‚     â”œâ”€â”€ upsert project by name
        â”‚     â”œâ”€â”€ pg_advisory_xact_lock(hashtext(pid || ':' || slug))
        â”‚     â”œâ”€â”€ SELECT COALESCE(MAX(version),0)+1
        â”‚     â””â”€â”€ INSERT build (status='running')
        â”œâ”€â”€ [phases 1-4: normalize â†’ validate â†’ generate â†’ heal]
        â”œâ”€â”€ store_artifact() Ã— 10
        â”œâ”€â”€ finalize_build(db, build_id, "success", ...)
        â””â”€â”€ return result dict
  â†’ db.commit() on success
  â†’ db.rollback() on exception
```

## Tables (db/schema.sql)

- **projects**: id uuid pk, name unique, created_at
- **builds**: id uuid pk, project_id fk, slug, version, original_request, status, confidence_score/grade, canonical_valid, export_valid, heal_attempts, failure_reason â€” UNIQUE(project_id, slug, version)
- **build_artifacts**: id uuid pk, build_id fk, artifact_type text, content_json jsonb, content_text text â€” UNIQUE(build_id, artifact_type)
- **assumptions**: id uuid pk, build_id fk, type, description, severity, created_at

## 10 Artifact Types Stored Per Build

canonical_spec, make_export, validation_report, export_validation_report,
confidence, build_log, timeline, cost_estimate, customer_delivery_summary, delivery_pack

## Dual Persistence

- **db_session provided** â†’ all artifacts go to PostgreSQL (production path)
- **db_session=None + base_output_dir** â†’ filesystem writes (self-test backward compat)
- Self-tests (`python -m tools.build_scenario_pipeline`) use filesystem, pass 8/8 checks

# ğŸ”§ KNOWN GAPS (NOT YET IMPLEMENTED)

- Authentication / authorization on API endpoints
- Agent reasoning layer (system is currently a deterministic compiler)
- canonical_spec_schema.json not wired for runtime validation
- assumption_tracker.py, delivery_adapter.py, generate_delivery_assessment.py built but not wired
- Confidence not recalculated after self-healing
- No structured logging, rate limiting, or concurrency protection beyond advisory locks
- 3 tools built but unused in pipeline

# ğŸ”— REPOSITORY

GitHub: https://github.com/Brian2169fdsa/agenticmakebuilder
